{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John compound\n",
      "eat ROOT\n",
      "mango dobj\n",
      "at prep\n",
      "9 nummod\n",
      "pm pobj\n",
      ". punct\n",
      "John NNP\n",
      "eat VB\n",
      "mango NN\n",
      "at IN\n",
      "9 CD\n",
      "pm NN\n",
      ". .\n",
      "Rabbit nsubj\n",
      "eat ROOT\n",
      "carrot dobj\n",
      "near prep\n",
      "the det\n",
      "Ganges compound\n",
      "river pobj\n",
      ". punct\n",
      "Rabbit NNP\n",
      "eat VB\n",
      "carrot NN\n",
      "near IN\n",
      "the DT\n",
      "Ganges NNP\n",
      "river NN\n",
      ". .\n",
      "John nsubj\n",
      "plays ROOT\n",
      "football dobj\n",
      ". punct\n",
      "John NNP\n",
      "plays VBZ\n",
      "football NN\n",
      ". .\n",
      "Harry compound\n",
      "studies ROOT\n",
      "in prep\n",
      "University_of_California pobj\n",
      ", punct\n",
      "Los compound\n",
      "Angeles appos\n",
      ". punct\n",
      "Harry NNP\n",
      "studies NNS\n",
      "in IN\n",
      "University_of_California NNP\n",
      ", ,\n",
      "Los NNP\n",
      "Angeles NNP\n",
      ". .\n",
      "Pierre nsubj\n",
      "teaches ROOT\n",
      "Jean dobj\n",
      "Pierre NNP\n",
      "teaches VBZ\n",
      "Jean NNP\n",
      "Narender compound\n",
      "Modi nsubj\n",
      "is ROOT\n",
      "Prime compound\n",
      "Minister ccomp\n",
      "of prep\n",
      "India pobj\n",
      "Narender NNP\n",
      "Modi NNP\n",
      "is VBZ\n",
      "Prime NNP\n",
      "Minister NNP\n",
      "of IN\n",
      "India NNP\n",
      "Barack compound\n",
      "Obama nsubj\n",
      "is ROOT\n",
      "President attr\n",
      "of prep\n",
      "the det\n",
      "US pobj\n",
      "Barack NNP\n",
      "Obama NNP\n",
      "is VBZ\n",
      "President NNP\n",
      "of IN\n",
      "the DT\n",
      "US NNP\n",
      "FullNameEntityDict {1: {'9pm': 'TIME', 'John': 'PERSON'}, 2: {'Ganges': 'LOC', 'Rabbit': 'PERSON'}, 3: {}, 4: {'Los Angeles': 'GPE', 'University_of_California': 'GPE', 'Harry': 'PERSON'}, 5: {'Pierre': 'PERSON', 'Jean': 'PERSON'}, 6: {'Narender Modi': 'PERSON', 'India': 'GPE'}, 7: {'Barack Obama': 'PERSON', 'US': 'GPE'}}\n",
      "FullSubjectObjectDict {1: {'pp': [at], 'verb': {'ROOT': eat}, 'object': ['mango', 'pm'], 'subject': ['John']}, 2: {'pp': [near], 'verb': {'ROOT': eat}, 'object': ['carrot', 'river'], 'subject': ['Rabbit', 'Ganges']}, 3: {'pp': [], 'verb': {'ROOT': plays}, 'object': ['football'], 'subject': ['John']}, 4: {'pp': [in], 'verb': {'ROOT': studies}, 'object': ['University_of_California'], 'subject': ['Harry', 'Los']}, 5: {'pp': [], 'verb': {'ROOT': teaches}, 'object': ['Jean'], 'subject': ['Pierre']}, 6: {'pp': [of], 'verb': {'ROOT': is}, 'object': ['India'], 'subject': ['Narender', 'Modi', 'Prime']}, 7: {'pp': [of], 'verb': {'ROOT': is}, 'object': ['US'], 'subject': ['Barack', 'Obama']}}\n",
      "1\n",
      "Who eat mango?\n",
      "What John eat?\n",
      "2\n",
      "Who eat carrot?\n",
      "What Rabbit eat?\n",
      "3\n",
      "4\n",
      "Who studies University_of_California?\n",
      "Where Harry studies?\n",
      "5\n",
      "Who teaches Jean?\n",
      "Whom Pierre teaches?\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "line_dict = {}\n",
    "line_noun_dict = {}\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "from spacy import *\n",
    "nlp=spacy.load('en')\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.corpus import stopwords\n",
    "import xml.dom.minidom as minidom\n",
    "#doc = minidom.parse('DevelopmentData_QuestionsFromSentences.xml')\n",
    "#itemlist = doc.getElementsByTagName('text') \n",
    "itemlist=['John eat mango at 9pm.','Rabbit eat carrot near the Ganges river.','John plays football.','Harry studies in University_of_California, Los Angeles.','Pierre teaches Jean','Narender Modi is Prime Minister of India']\n",
    "itemlist.append('Barack Obama is President of the US')\n",
    "result=''\n",
    "res = []\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# tokenizer = RegexpTokenizer(r'\\w+')\n",
    "j = 0\n",
    "noun_chunk = {}\n",
    "FullNameEntityDict = {}\n",
    "FullSubjectObjectDict = {}\n",
    "subject_dict = {}\n",
    "lis = []\n",
    "for i in itemlist:\n",
    "#     memoryElem = i\n",
    "    j=j+1\n",
    "#     result=''.join( [node.data for node in memoryElem.childNodes] )\n",
    "#     result=itemlist[i]\n",
    "#     print(\"result\",result)\n",
    "    res = nlp(i)\n",
    "#     print(\"res\",res)\n",
    "    line_dict[j] = result\n",
    "    tempDict={}\n",
    "    for np in res.ents:\n",
    "        tempDict.update({str(np):np.label_})\n",
    "\n",
    "    FullNameEntityDict[j] = tempDict\n",
    "    \n",
    "    #get token dependencies\n",
    "    so_obj_Dict={}\n",
    "    subjects=[]\n",
    "    objects=[]\n",
    "    verb_tag_Dict={} #stores words with verb tag\n",
    "    for text in res:\n",
    "        print(text,text.dep_)\n",
    "        if text.dep_ == \"nsubj\" or text.dep_=='npadvmod' or text.dep_=='compound':\n",
    "            #subject would be\n",
    "            subject = text.orth_\n",
    "            subjects.append(subject)\n",
    "#             print(\"subject\",subject)\n",
    "#             lis.append(subject)\n",
    "#             so_obj_Dict.update({\"subject\":subject})\n",
    "        elif (re.match(r'.obj',text.dep_)):\n",
    "            #iobj for indirect object\n",
    "            any_object = text.orth_\n",
    "            objects.append(any_object)\n",
    "#             print(\"iobj\",indirect_object)\n",
    "#             lis.append(indirect_object)\n",
    "            so_obj_Dict.update({\"object\":any_object})\n",
    "        elif (re.match(r'VB',text.dep_)or re.match(r'ROOT',text.dep_)):\n",
    "            #iobj for indirect object\n",
    "            verb_tag_Dict.update({text.dep_:text})\n",
    "#             print(\"iobj\",indirect_object)\n",
    "#             lis.append(indirect_object)\n",
    "        \n",
    "        so_obj_Dict.update({\"object\":objects})\n",
    "        so_obj_Dict.update({\"subject\":subjects})\n",
    "        so_obj_Dict.update({\"verb\":verb_tag_Dict}) \n",
    "        \n",
    "    \n",
    "    pp_tag_List=[]   #stores words with prepositions tag\n",
    "    for word in list(res.sents)[0]:\n",
    "        print(word,word.tag_)\n",
    "        '''if(re.match(r'^VB*',word.tag_)):\n",
    "#             print(\"word.tag_\",word.tag_)\n",
    "            verb_tag_Dict.update({word.tag_:word})'''\n",
    "            #word_tag_dict[word]=word.tag_\n",
    "        if(re.match(r'IN',word.tag_)):\n",
    "#             print(\"word.tag_\",word.tag_)\n",
    "            pp_tag_List.append(word)\n",
    "            #word_tag_dict[word]=word.tag_\n",
    "        \n",
    "        so_obj_Dict.update({\"pp\":pp_tag_List}) \n",
    "    #print(so_obj_Dict)\n",
    "    FullSubjectObjectDict[j] = so_obj_Dict\n",
    "    #subject_dict[j]=lis\n",
    "print(\"FullNameEntityDict\",FullNameEntityDict)\n",
    "print(\"FullSubjectObjectDict\",FullSubjectObjectDict)\n",
    "\n",
    "# print(\"FullNameEntityDict\",FullNameEntityDict)\n",
    "# print(FullSubjectObjectDict)\n",
    "#Person-Person- :Who + verb + object\n",
    "for i in range (1,len(FullSubjectObjectDict)+1):\n",
    "    print(i)\n",
    "    tempDict=FullSubjectObjectDict.get(i)\n",
    "    #print(tempDict)\n",
    "    subTempList=tempDict['subject']\n",
    "    objTempList=tempDict['object']\n",
    "    ppTempList=tempDict['pp']\n",
    "    verbTempDict=tempDict['verb']\n",
    "    \n",
    "    temp={}\n",
    "    if(len(subTempList)!=0 and len(objTempList)!=0 and len(ppTempList)!=0):\n",
    "        if(FullNameEntityDict.get(i).get(subTempList[0])=='PERSON' and FullNameEntityDict.get(i).get(objTempList[0])!='PERSON'):\n",
    "            if(verbTempDict.get('ROOT')!=None):\n",
    "#                 print(\"1\")\n",
    "                print('Who '+str(verbTempDict.get('ROOT'))+' '+str(objTempList[0])+'?')\n",
    "                if(FullNameEntityDict.get(i).get(objTempList[0])=='GPE'):\n",
    "                    print('Where '+str(subTempList[0])+' '+str(verbTempDict.get('ROOT'))+'?')\n",
    "                else:\n",
    "                    print('What '+str(subTempList[0])+' '+str(verbTempDict.get('ROOT'))+'?')\n",
    "            if(verbTempDict.get('VB')!=None):\n",
    "#                 print(\"2\")\n",
    "                print('Who '+str(verbTempDict.get('VB'))+' '+str(objTempList[0])+'?')\n",
    "                print('What '+str(subTempList[0])+' '+str(verbTempDict.get('VB'))+'?')\n",
    "            \n",
    "                \n",
    "    elif(len(subTempList)!=0 and len(objTempList)!=0 and len(ppTempList)==0):\n",
    "        if(FullNameEntityDict.get(i).get(subTempList[0])=='PERSON' and FullNameEntityDict.get(i).get(objTempList[0])=='PERSON'):\n",
    "            if(verbTempDict.get('ROOT')!=None):\n",
    "#                 print(\"3\")\n",
    "                print('Who '+str(verbTempDict.get('ROOT'))+' '+str(objTempList[0])+'?')\n",
    "                print('Whom '+str(subTempList[0])+' '+str(verbTempDict.get('ROOT'))+'?')\n",
    "        elif(FullNameEntityDict.get(i).get(subTempList[0])=='PERSON' and FullNameEntityDict.get(i).get(objTempList[0])!='PERSON'):\n",
    "            if(verbTempDict.get('ROOT')!=None):\n",
    "#                 print(\"4\")\n",
    "                print('Who '+str(verbTempDict.get('ROOT'))+ ' '+str(objTempList[0])+'?')\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
